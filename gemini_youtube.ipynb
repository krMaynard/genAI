{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4zIoAxA/yn3A3+Id9f+Jd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krMaynard/genai/blob/main/gemini_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I-bVK7ebQ04s"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import textwrap\n",
        "from io import BytesIO\n",
        "\n",
        "# Third-party imports\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "secret_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=secret_api_key)\n",
        "\n",
        "prompts = []\n",
        "responses = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = textwrap.dedent(\"\"\"\\\n",
        "  Create a detailed outline of all the topics presented in the video,\n",
        "  as a study guide for a highly motivated and technically knowledgeable\n",
        "  student to further their knowledge of GenAI and practical applications.\\\n",
        "\"\"\")\n",
        "\n",
        "VIDEO_URL = 'https://www.youtube.com/watch?v=9-eXLFvAoKM&t=381s'\n",
        "\n",
        "MODEL = 'models/gemini-2.5-flash'"
      ],
      "metadata": {
        "id": "yOw3L2GBYkQo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_video(prompt,url):\n",
        "  prompts.append(prompt)\n",
        "  response = client.models.generate_content(\n",
        "      model=MODEL,\n",
        "      contents=types.Content(\n",
        "          parts=[\n",
        "              types.Part(\n",
        "                  file_data=types.FileData(file_uri=url)\n",
        "              ),\n",
        "              types.Part(text=prompt)\n",
        "          ]\n",
        "      )\n",
        "  )\n",
        "  responses.append(response)\n",
        "  return response"
      ],
      "metadata": {
        "id": "vcO0z9owYhI4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = prompt_video(PROMPT,VIDEO_URL)"
      ],
      "metadata": {
        "id": "qr3R9ZXpZB_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_summary = response.text"
      ],
      "metadata": {
        "id": "9CYTwzqJlDjQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(text):\n",
        "  display(Markdown(text))\n",
        "\n",
        "printmd(video_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HEteEFsNYoXw",
        "outputId": "3e53cdbf-de3b-4cf7-a014-320cd30d9d66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This outline provides a comprehensive study guide based on the video's content, aimed at a technically knowledgeable student seeking to deepen their understanding of Generative AI from both research and practical deployment perspectives.\n\n---\n\n## Study Guide: Making GenAI Useful - Lessons from Research and Deployment\n\n**Video Overview:** This session explores the practical challenges and breakthroughs in making Generative AI (GenAI) useful, drawing insights from leading experts in both academia and industry. The discussion covers common misunderstandings about LLM behavior, the critical role of post-training, evaluation methodologies, and the societal implications of AI development.\n\n**Speakers:**\n*   **Aditya Challapally** (Microsoft, Machine Learning Engineer & Product Lead; Stanford GenAI course instructor, Moderator)\n*   **Michelle Pokrass** (OpenAI, Post-Training Research Lead; oversees efforts to align models for technical, high-demand use cases across ChatGPT and API)\n*   **Christopher Potts** (Stanford University, Professor of Linguistics & by courtesy Computer Science; researches computational models of linguistic reasoning, emotional expression, and dialogue; Stanford GenAI program instructor)\n\n---\n\n### I. Introduction to GenAI Usefulness\n\n*   **A. Purpose of the Discussion:**\n    *   To provide perspectives on LLMs from both academic research and industry deployment.\n    *   To identify useful deployments and areas for improvement.\n    *   To discuss future directions in GenAI.\n*   **B. Key Areas of Focus:**\n    1.  How language model behavior is shaped.\n    2.  Most useful GenAI deployments observed.\n    3.  How to improve GenAI products and models.\n\n---\n\n### II. Understanding Language Model Behavior and Shaping\n\n*   **A. Common Misconceptions (Aditya Challapally's opening question):**\n    *   How is language model behavior actually shaped, beyond common understanding?\n\n*   **B. Chris Potts (Academic Perspective):**\n    *   **Underestimated Potential of Base Models:**\n        *   Models *before* extensive post-training possess significant latent capabilities.\n        *   They are less predictable than post-trained models, often requiring more \"context engineering\" (prompting).\n        *   However, their raw creativity can be surprising for certain tasks.\n        *   Current API access often limits direct interaction with pure base models, which is a missed opportunity for exploration.\n    *   **The Role of Post-Training:**\n        *   Post-training is primarily about \"surfacing\" or aligning the inherent capabilities of base models.\n        *   **Supervised Fine-Tuning (SFT):**\n            *   A powerful, predictable, and controllable method for shaping behavior.\n            *   Often used in conjunction with more advanced Reinforcement Learning (RL) algorithms.\n            *   Emphasizes the crucial role of **data curation** for successful fine-tuning.\n\n*   **C. Michelle Pokrass (Industry Perspective - OpenAI):**\n    *   **Defining Key Terms:**\n        *   **Base Model:** The outcome of the pre-training phase (e.g., next-token prediction on a massive text corpus). Represents the \"rawest form of intelligence.\"\n            *   *Challenge:* While intelligent, they are \"very challenging to use\" for specific tasks (e.g., asking \"How do I ride a bike?\" might yield \"How do I drive a car?\" completions).\n        *   **Post-training:** The subsequent phase focused on aligning models with human preferences and eliciting specific, useful capabilities.\n            *   **ChatGPT as a Turning Point:** It was the first instance where models were \"aligned and easy to talk to,\" making their underlying intelligence widely accessible.\n    *   **Misconception about Model Development:**\n        *   People often view LLM development like traditional software development (define a spec, train, get an exact output).\n        *   **Reality:** LLM capabilities are largely \"emergent properties of scale.\" Specific abilities (like coding in GPT-4) weren't always pre-planned but arose from the sheer volume and complexity of training.\n    *   **Specific Improvements in GPT-4.1 (focused on developers):**\n        *   **Better Long-Context Performance:** Models could process and understand larger amounts of input (e.g., entire codebases or documentation).\n        *   **Tool Calling:** Improved ability to correctly identify and use external tools, demonstrating greater robustness and persistence even with complex tasks.\n        *   **Coding Proficiency:** Significant improvement in generating and understanding code.\n        *   **Instruction Following:** Enhanced ability to adhere to complex, multi-step instructions, vital for developer workflows.\n    *   **Evaluation and Iteration:**\n        *   OpenAI developed custom \"internal evals\" based on real-world *production use cases* and direct feedback from developers.\n        *   Rapid \"alpha\" releases and iterative refinement cycles (e.g., weekly updates based on developer complaints) were crucial for achieving alignment.\n\n---\n\n### III. Measuring Usefulness and Navigating Ethical Considerations\n\n*   **A. The \"System\" Matters More Than Just the \"Model\" (Chris Potts):**\n    *   The overall user experience (and thus \"usefulness\") is determined by the model *and* the surrounding software and system design.\n    *   A highly capable model can lead to a poor user experience if the system around it is poorly designed (e.g., bad sampling, lack of guardrails).\n    *   Conversely, a less powerful model can be made highly useful by an exceptionally well-designed system.\n    *   This includes aspects like access to tools, effective tool utilization by the model, and the inherent capabilities of the tools themselves.\n    *   **Balancing Generalization vs. Truthfulness/Fidelity:**\n        *   There's a tension: some tasks (e.g., information retrieval, fact-checking) demand strict adherence to facts/sources.\n        *   Other tasks (e.g., brainstorming, creative writing) benefit from the model's ability to \"stray\" or generate novel ideas.\n        *   The challenge is managing this tension based on the specific application's needs.\n    *   **The \"Vigilance\" Problem (Societal Risk):**\n        *   As models become increasingly competent and their errors rarer (e.g., 1 in 100 or 1 in 1000 outputs), users may become less vigilant in checking outputs.\n        *   This creates a \"dangerous moment\" where subtle errors or biases can go unnoticed, potentially leading to significant consequences.\n        *   Models, like humans, are fallible, and this needs to be acknowledged and managed.\n\n*   **B. Who Defines \"Good Behavior\" (Michelle Pokrass):**\n    *   **The Impossibility of \"Bias-Free\":** It's impossible to create a model that is truly \"bias-free\" from every person on Earth's perspective, as human values and priors are diverse.\n    *   **The Importance of Steerability:** Models should be designed to be \"steerable\" so that users and developers can align them with their specific needs and values.\n    *   **The \"Model Spec\" (Continued):**\n        *   An open-sourced document that outlines the *intended* behaviors and principles of OpenAI's models.\n        *   Continuously updated through iterative feedback from the diverse user base.\n    *   **The \"Emergent\" Nature of Capabilities:** The exact capabilities and limitations of models often emerge as they scale, rather than being fully pre-defined. This requires continuous evaluation and adaptation.\n    *   **The \"AI Era\" and User Expectations:** As AI becomes more pervasive, users are becoming \"AI-native\" and developing stronger opinions about how models should behave.\n    *   **Striving for Usability and Steerability:**\n        *   Models should be helpful, usable, and steerable.\n        *   Focus on ensuring models follow instructions, even negative ones (e.g., \"never say 'I am a large language model'\").\n        *   This sometimes involves fixing inconsistencies or contradictions within the model's internal representations or how instructions are interpreted.\n    *   **Transparency is Key:** Making the model's sources visible in the UI (e.g., citations) allows users to verify information and build trust.\n\n### IV. Practical Advice for Building with GenAI & Future Outlook\n\n*   **A. Best Practices for Model Building (Chris Potts):**\n    *   **Do Not Over-Cleanse Data:** Trying to remove all \"problematic\" content (e.g., swearing) from training data can make models naive and unable to interact appropriately with those concepts.\n    *   **Exposure + Instruction:** Models need exposure to a wide range of real-world data and explicit instructions on desired behaviors to learn effectively.\n    *   **Unit Tests for LLMs:**\n        *   Think like a software engineer: write small, specific unit tests for model behavior.\n        *   Even a \"dozen cases\" are better than zero for evaluation.\n        *   Focus on test cases that are meaningful to *your* use case, not just generic benchmarks.\n        *   This allows for faster iteration and understanding of model performance.\n    *   **Beyond the \"Vibe Check\":** Don't just rely on intuition; systematically evaluate.\n    *   **Leverage Synthetic Data:** A powerful tool for creating diverse and targeted evaluation sets when human-labeled data is scarce.\n    *   **Diverse Models:** Experiment with different model architectures and training approaches to find optimal performance.\n\n*   **B. Best Practices for Application Development (Michelle Pokrass):**\n    *   **Focus on the \"Systems Around the Model\":** Successful AI products prioritize building robust and user-friendly interfaces and infrastructure around the core LLM.\n    *   **LLM Judges for Evals:** Using LLMs themselves to evaluate model outputs can be highly effective, but requires careful evaluation of the \"judge\" model's own biases and reliability.\n    *   **\"Capabilities Overhang\":** Many enterprise use cases already have solutions possible with current models, but the integration and usability layers are missing.\n    *   **Investment in Platform Primitives:** Developers need access to powerful and easy-to-use tools (e.g., vector databases, file search, structured output formatting like JSON) to connect LLMs to real-world applications.\n    *   **Move Fast with Synthetic Data:** For startups, rapid iteration is key. Using synthetic data for quick experimentation and evaluation can accelerate development.\n    *   **Focus on Niche Verticals:** Instead of trying to build a general-purpose AI, focus on specific industries or problem domains where AI can provide immediate value.\n    *   **Iterative Product Development:** Continuously gather feedback, analyze discrepancies, and refine the model and system.\n    *   **Transparency and Explainability (Future Work):** Making model outputs traceable and understandable (e.g., showing which tools or documents were used) is crucial for building trust and allowing users to debug.\n    *   **Societal Evolution:** As society becomes more \"AI-native,\" expectations and demands on models will continue to evolve, requiring ongoing adaptation of models and their \"specs.\"\n\n---"
          },
          "metadata": {}
        }
      ]
    }
  ]
}